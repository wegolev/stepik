import re
TOKENIZE_RE = re.compile(r'[а-яА-ЯёЁ]+|-?\d*[.,]?\d+|\S', re.I)

tests = {
    'абв123': ['абв', '123'],
    '123абв': ['123', 'абв'],
    '-123абв': ['-123', 'абв'],
    '123.23': ['123.23'],
    '123,23': ['123,23'],
    'Мама мыла -56.035 раму.': ['мама', 'мыла', '-56.035', 'раму', '.'],
    'Мама мыла -56,035 раму.': ['мама', 'мыла', '-56,035', 'раму', '.'],
    'Мама мыла -.035 раму.': ['мама', 'мыла', '-.035', 'раму', '.'],
    'Мама мыла -,035 раму.': ['мама', 'мыла', '-,035', 'раму', '.'],
    'Мама (ну та самая) мыла раму!': ['мама', '(', 'ну', 'та', 'самая', ')', 'мыла', 'раму', '!'],
    'Мама мыла раму.': ['мама', 'мыла', 'раму', '.'],
    'Мама_мыла_раму.': ['мама', '_', 'мыла', '_', 'раму', '.'],
    'Это мама, которая    мыла раму 3раза? Да, всё-таки это - она! Офигеть...': ['это', 'мама', ',', 'которая', 'мыла', 'раму', '3', 'раза', '?', 'да', ',', 'всё', '-', 'таки', 'это', '-', 'она', '!', 'офигеть', '.', '.', '.'],
    'вот такая дробь .52': ['вот', 'такая', 'дробь', '.52'],
    'и вот такая дробь -.52': ['и', 'вот', 'такая', 'дробь', '-.52'],
    'Согласно ст.89 §§ 22-24 и 27 следует...': ['согласно', 'ст', '.89', '§', '§', '22', '-24', 'и', '27', 'следует', '.', '.', '.'],
    'вот такая дробь 0.52': ['вот', 'такая', 'дробь', '0.52'],
    'а это вроде и не дробь 25.': ['а', 'это', 'вроде', 'и', 'не', 'дробь', '25', '.'],          
    'абв абв123 123 .123 -.123 -.123/123 123/1234 -123/1234 1.123 -1.123 123. -123. ..... ,,,,,': \
    ['абв', 'абв', '123', '123', '.123', '-.123', '-.123', '/', '123', 
     '123', '/', '1234', '-123', '/', '1234', '1.123', '-1.123', '123', 
     '.', '-123', '.', '.', '.', '.', '.', '.', ',', ',', ',', ',', ','],
    """Список:
    1. Пункт №1* (со звёздочкой) ;
    2. Пункт второй [#2] 2 < 3 & 2 > 1;
    3.Пункт третий {и последний}""": \
    ['список', ':', '1', '.', 'пункт', '№', '1', '*', '(', 'со', 'звёздочкой',
     ')', ';', '2', '.', 'пункт', 'второй', '[', '#', '2', ']', '2', '<', '3',
     '&', '2', '>', '1', ';', '3', '.', 'пункт', 'третий', '{', 'и', 'последний', '}'],
#     'везучий случай': ['везучии', '̆', 'случай'],
    '': []
}

def tokenize(txt):
    return TOKENIZE_RE.findall(txt)


for test in tests:
    tokens = tokenize(test.strip().lower())
    try:
        assert tokens == tests[test]
        print(f'{test} - ТЕСТ ПРОЙДЕН')
    except AssertionError:
        print(f'{test} - ТЕСТ ПРОВАЛЕН')
        print('Ожидается:')
        print(tests[test])
        print('Получено:')
        print(tokens)