{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Создаем входной массив из двух изображений RGB 3*3\n",
    "input_images = torch.tensor(\n",
    "      [[[[0,  1,  2],\n",
    "         [3,  4,  5],\n",
    "         [6,  7,  8]],\n",
    "\n",
    "        [[9, 10, 11],\n",
    "         [12, 13, 14],\n",
    "         [15, 16, 17]],\n",
    "\n",
    "        [[18, 19, 20],\n",
    "         [21, 22, 23],\n",
    "         [24, 25, 26]]],\n",
    "\n",
    "\n",
    "       [[[27, 28, 29],\n",
    "         [30, 31, 32],\n",
    "         [33, 34, 35]],\n",
    "\n",
    "        [[36, 37, 38],\n",
    "         [39, 40, 41],\n",
    "         [42, 43, 44]],\n",
    "\n",
    "        [[45, 46, 47],\n",
    "         [48, 49, 50],\n",
    "         [51, 52, 53]]]])\n",
    "\n",
    "# print(input_images.size())\n",
    "input_images = input_images.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5, 5])\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  1.,  2.,  0.],\n",
      "          [ 0.,  3.,  4.,  5.,  0.],\n",
      "          [ 0.,  6.,  7.,  8.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  9., 10., 11.,  0.],\n",
      "          [ 0., 12., 13., 14.,  0.],\n",
      "          [ 0., 15., 16., 17.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 18., 19., 20.,  0.],\n",
      "          [ 0., 21., 22., 23.,  0.],\n",
      "          [ 0., 24., 25., 26.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 27., 28., 29.,  0.],\n",
      "          [ 0., 30., 31., 32.,  0.],\n",
      "          [ 0., 33., 34., 35.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 36., 37., 38.,  0.],\n",
      "          [ 0., 39., 40., 41.,  0.],\n",
      "          [ 0., 42., 43., 44.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 45., 46., 47.,  0.],\n",
      "          [ 0., 48., 49., 50.,  0.],\n",
      "          [ 0., 51., 52., 53.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]]])\n"
     ]
    }
   ],
   "source": [
    "def get_padding2d(input_images):\n",
    "    padded_images = torch.nn.functional.pad (input_images,\n",
    "                                             (1, 1, 1, 1),\n",
    "                                             mode = \"constant\",\n",
    "                                             value = 0.0)\n",
    "    return padded_images\n",
    "\n",
    "print(get_padding2d(input_images).size())\n",
    "print(get_padding2d(input_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "correct_padded_images = torch.tensor(\n",
    "       [[[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  0.,  1.,  2.,  0.],\n",
    "          [0.,  3.,  4.,  5.,  0.],\n",
    "          [0.,  6.,  7.,  8.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  9., 10., 11.,  0.],\n",
    "          [0., 12., 13., 14.,  0.],\n",
    "          [0., 15., 16., 17.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 18., 19., 20.,  0.],\n",
    "          [0., 21., 22., 23.,  0.],\n",
    "          [0., 24., 25., 26.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]],\n",
    "\n",
    "\n",
    "        [[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 27., 28., 29.,  0.],\n",
    "          [0., 30., 31., 32.,  0.],\n",
    "          [0., 33., 34., 35.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 36., 37., 38.,  0.],\n",
    "          [0., 39., 40., 41.,  0.],\n",
    "          [0., 42., 43., 44.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 45., 46., 47.,  0.],\n",
    "          [0., 48., 49., 50.,  0.],\n",
    "          [0., 51., 52., 53.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]]])\n",
    "\n",
    "# print(correct_padded_images)\n",
    "\n",
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "print(torch.allclose(get_padding2d(input_images), correct_padded_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
