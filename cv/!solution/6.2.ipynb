{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 Семинар: cлой нормализации\n",
    "4 из 11 шагов пройдено\n",
    "2 из 8 баллов  получено\n",
    "\n",
    "В этом уроке мы детально изучим слои нормализации.\n",
    "\n",
    "Самая популярная версия слоя нормализации - слой нормализации \"по батчу\" (batch-norm слой).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном шаге вам требуется реализовать функцию батч-нормализации без использования стандартной функции со следующими упрощениями:\n",
    "\n",
    "Параметр Бета принимается равным 0.\n",
    "Параметр Гамма принимается равным 1.\n",
    "Функция должна корректно работать только на этапе обучения.\n",
    "Вход имеет размерность число элементов в батче * длина каждого инстанса.\n",
    " \n",
    "Очень внимательно посмотрите на определение функции, вычисляющей std.\n",
    "\n",
    "Sample Input: anything\n",
    "\n",
    "Sample Output: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def custom_batch_norm1d(input_tensor, eps):\n",
    "    mean = input_tensor.mean(dim=0)\n",
    "    var = input_tensor.var(dim=0, unbiased=False)\n",
    "    \n",
    "    normed_tensor = (input_tensor - mean) / torch.sqrt(var + eps)\n",
    "    return normed_tensor\n",
    "\n",
    "\n",
    "input_tensor = torch.Tensor([[0.0, 0, 1, 0, 2], [0, 1, 1, 0, 10]])\n",
    "batch_norm = nn.BatchNorm1d(input_tensor.shape[1], affine=False)\n",
    "\n",
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "# import numpy as np\n",
    "# all_correct = True\n",
    "# for eps_power in range(10):\n",
    "#     eps = np.power(10., -eps_power)\n",
    "#     batch_norm.eps = eps\n",
    "#     batch_norm_out = batch_norm(input_tensor)\n",
    "#     custom_batch_norm_out = custom_batch_norm1d(input_tensor, eps)\n",
    "\n",
    "#     all_correct &= torch.allclose(batch_norm_out, custom_batch_norm_out)\n",
    "#     all_correct &= batch_norm_out.shape == custom_batch_norm_out.shape\n",
    "# print(all_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 Семинар: cлой нормализации\n",
    "4 из 11 шагов пройдено\n",
    "2 из 8 баллов  получено\n",
    "\n",
    "Немного обобщим функцию с предыдущего шага - добавим возможность задавать параметры Бета и Гамма.\n",
    "\n",
    "На данном шаге вам требуется реализовать функцию батч-нормализации без использования стандартной функции со следующими упрощениями:\n",
    "\n",
    "Функция должна корректно работать только на этапе обучения.\n",
    "Вход имеет размерность число элементов в батче * длина каждого инстанса.\n",
    "\n",
    "Sample Input: anything\n",
    "\n",
    "Sample Output: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = 7\n",
    "batch_size = 5\n",
    "input_tensor = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "\n",
    "eps = 1e-3\n",
    "\n",
    "def custom_batch_norm1d(input_tensor, weight, bias, eps):\n",
    "    # Шаг 1: Вычисление среднего значения\n",
    "    mean = input_tensor.mean(dim=0)\n",
    "    \n",
    "    # Шаг 2: Вычетание среднего значения\n",
    "    centered_input = input_tensor - mean\n",
    "    \n",
    "    # Шаг 3: Вычисление дисперсии и нормализация\n",
    "    variance = centered_input.pow(2).mean(dim=0)\n",
    "    stddev = torch.sqrt(variance + eps)\n",
    "    normalized_input = centered_input / stddev\n",
    "    \n",
    "    # Шаги 4 и 5: Применение весового коэффициента и смещения\n",
    "    normed_tensor = weight * normalized_input + bias\n",
    "    \n",
    "    return normed_tensor\n",
    "\n",
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "# batch_norm = nn.BatchNorm1d(input_size, eps=eps)\n",
    "# batch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\n",
    "# batch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\n",
    "# batch_norm_out = batch_norm(input_tensor)\n",
    "# custom_batch_norm_out = custom_batch_norm1d(input_tensor, batch_norm.weight.data, batch_norm.bias.data, eps)\n",
    "# print(torch.allclose(batch_norm_out, custom_batch_norm_out, 1e-3) \\\n",
    "#       and batch_norm_out.shape == custom_batch_norm_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 Семинар: cлой нормализации\n",
    "4 из 11 шагов пройдено\n",
    "2 из 8 баллов  получено\n",
    "\n",
    "Избавимся еще от одного упрощения - реализуем работу слоя батч-нормализации на этапе предсказания.\n",
    "\n",
    "На этом этапе вместо статистик по батчу будем использовать экспоненциально сглаженные статистики из истории обучения слоя.\n",
    "\n",
    "В данном шаге вам требуется реализовать полноценный класс батч-нормализации без использования стандартной функции, принимающий на вход двумерный тензор. Осторожно, расчёт дисперсии ведётся по смещенной выборке, а расчет скользящего среднего по несмещенной.\n",
    "\n",
    "Sample Input: anything\n",
    "\n",
    "Sample Output: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "input_size = 3\n",
    "batch_size = 5\n",
    "eps = 1e-1\n",
    "\n",
    "\n",
    "class CustomBatchNorm1d:\n",
    "    def __init__(self, weight, bias, eps, momentum):\n",
    "        # Реализуйте в этом месте конструктор.\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        normed_tensor = # Напишите в этом месте нормирование входного тензора.\n",
    "\n",
    "    def eval(self):\n",
    "        # В этом методе реализуйте переключение в режим предикта.\n",
    "\n",
    "\n",
    "batch_norm = nn.BatchNorm1d(input_size, eps=eps)\n",
    "batch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm.momentum = 0.5\n",
    "\n",
    "custom_batch_norm1d = CustomBatchNorm1d(batch_norm.weight.data,\n",
    "                                        batch_norm.bias.data, eps, batch_norm.momentum)\n",
    "\n",
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "# all_correct = True\n",
    "\n",
    "# for i in range(8):\n",
    "#     torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "#     norm_output = batch_norm(torch_input)\n",
    "#     custom_output = custom_batch_norm1d(torch_input)\n",
    "#     all_correct &= torch.allclose(norm_output, custom_output, atol=1e-04) \\\n",
    "#         and norm_output.shape == custom_output.shape\n",
    "\n",
    "# batch_norm.eval()\n",
    "# custom_batch_norm1d.eval()\n",
    "\n",
    "# for i in range(8):\n",
    "#     torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "#     norm_output = batch_norm(torch_input)\n",
    "#     custom_output = custom_batch_norm1d(torch_input)\n",
    "#     all_correct &= torch.allclose(norm_output, custom_output, atol=1e-04) \\\n",
    "#         and norm_output.shape == custom_output.shape\n",
    "# print(all_correct)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomBatchNorm1d:\n",
    "    def __init__(self, weight, bias, eps, momentum):\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.running_mean = torch.zeros(weight.shape[0])\n",
    "        self.running_var = torch.ones(weight.shape[0])\n",
    "        self.is_training = True\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        if self.is_training:\n",
    "            # Расчёт текущих средних и дисперсий\n",
    "            batch_mean = input_tensor.mean(dim=0)\n",
    "            batch_var = ((input_tensor - batch_mean) ** 2).mean(dim=0)\n",
    "\n",
    "            # Обновление экспоненциальных средних\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * batch_mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * batch_var\n",
    "            # (1-momentum)*var*batch_size/(batch_size-1)+momentum*running_var\n",
    "\n",
    "            # Смещённая оценка дисперсии\n",
    "            biased_var = batch_var * (input_tensor.size(0) / (input_tensor.size(0) - 1))\n",
    "\n",
    "            # Нормализация\n",
    "            normed_tensor = (input_tensor - batch_mean) / torch.sqrt(biased_var + self.eps)\n",
    "        else:\n",
    "            # Использование экспоненциально сглаженных средних и дисперсий\n",
    "            normed_tensor = (input_tensor - self.running_mean) / torch.sqrt(self.running_var + self.eps)\n",
    "\n",
    "        # Применение весов и смещений\n",
    "        normed_tensor = self.weight * normed_tensor + self.bias\n",
    "\n",
    "        return normed_tensor\n",
    "\n",
    "    def eval(self):\n",
    "        self.is_training = False\n",
    "\n",
    "# Настройки\n",
    "input_size = 3\n",
    "batch_size = 5\n",
    "eps = 1e-1\n",
    "\n",
    "# Стандартный слой батч-нормализации\n",
    "batch_norm = nn.BatchNorm1d(input_size, eps=eps)\n",
    "batch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm.momentum = 0.5\n",
    "\n",
    "# Пользовательский слой батч-нормализации\n",
    "custom_batch_norm1d = CustomBatchNorm1d(\n",
    "    batch_norm.weight.data,\n",
    "    batch_norm.bias.data,\n",
    "    eps,\n",
    "    batch_norm.momentum\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "custom_output\n",
      " tensor([[ 0.4575,  0.5046, -0.1942],\n",
      "        [ 0.2927, -2.6247, -0.0287],\n",
      "        [-0.1823,  1.8898, -0.2639],\n",
      "        [ 0.3403,  1.4986, -0.4484],\n",
      "        [-0.4431, -0.1873, -0.4977]])\n",
      "norm_output\n",
      " tensor([[ 0.4066,  0.4778, -0.1743],\n",
      "        [ 0.2574, -2.3622, -0.0239],\n",
      "        [-0.1724,  1.7349, -0.2377],\n",
      "        [ 0.3005,  1.3799, -0.4053],\n",
      "        [-0.4084, -0.1502, -0.4501]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "all_correct = True\n",
    "\n",
    "for i in range(8):\n",
    "    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "    norm_output = batch_norm(torch_input)\n",
    "    custom_output = custom_batch_norm1d(torch_input)\n",
    "    all_correct &= torch.allclose(norm_output, custom_output, atol=1e-04) \\\n",
    "        and norm_output.shape == custom_output.shape\n",
    "\n",
    "batch_norm.eval()\n",
    "custom_batch_norm1d.eval()\n",
    "\n",
    "for i in range(8):\n",
    "    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "    norm_output = batch_norm(torch_input)\n",
    "    custom_output = custom_batch_norm1d(torch_input)\n",
    "    all_correct &= torch.allclose(norm_output, custom_output, atol=1e-04) \\\n",
    "        and norm_output.shape == custom_output.shape\n",
    "print(all_correct)\n",
    "\n",
    "print(\"custom_output\\n\", custom_output)\n",
    "print(\"norm_output\\n\", norm_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
